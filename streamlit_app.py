# -----------------------------------------------------------------------------
# streamlit_app.py ‚Äî Buscador inteligente de concursos p√∫blicos (RAG + GPT‚Äë4)
# -----------------------------------------------------------------------------
# Este script ofrece una interfaz Streamlit para consultar un vectorstore Chroma
# de contratos p√∫blicos. Incluye:
#   ‚Ä¢ Reformulaci√≥n e identificaci√≥n de intenci√≥n (c√≥digo vs servicio)
#   ‚Ä¢ B√∫squeda por regex o b√∫squeda sem√°ntica (embeddings OpenAI)
#   ‚Ä¢ Validaci√≥n / rerank de resultados con GPT‚Äë4
#   ‚Ä¢ Tabla interactiva + visualizaci√≥n 3D opcional (PCA)
#   ‚Ä¢ Todo configurable desde la sidebar (vectorstore y OPENAI_API_KEY)
# -----------------------------------------------------------------------------

from __future__ import annotations
import importlib, sys, os, re, json
from typing import List, Dict, Any, Tuple

# --- Parche sqlite3 para entornos sin la librer√≠a nativa ---------------------
try:
    import pysqlite3  # type: ignore
    sys.modules["sqlite3"] = importlib.import_module("pysqlite3")
    sys.modules["sqlite3.dbapi2"] = sys.modules["sqlite3"]
except ImportError:
    pass

# --------------------------- Dependencias externas ---------------------------

import streamlit as st
import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
import plotly.graph_objects as go
from sklearn.metrics.pairwise import cosine_similarity

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser

# --------------------------- Constantes globales -----------------------------

EMBEDDING_MODEL   = "text-embedding-3-small"
EMBEDDING_DIM     = 1024           # Reducimos tama√±o para ahorrar memoria
MAX_TOP_K         = 20             # L√≠mite superior de resultados a mostrar
DEFAULT_TOP_K     = 5

# =========================== INTERFAZ DE USUARIO =============================

st.set_page_config(page_title="Buscador Concursos P√∫blicos", layout="wide")

# --- Sidebar ----------------------------------------------------------------
st.sidebar.title("‚öôÔ∏è Configuraci√≥n")
vectorstore_path = st.sidebar.text_input("Ruta del vectorstore", "./chroma")
api_key          = st.sidebar.text_input("OPENAI_API_KEY", type="password")
show_pca         = st.sidebar.checkbox("Mostrar visualizaci√≥n 3D (PCA)")

st.sidebar.markdown(
    """üß† **Modelo embeddings**: `text-embedding-3-small`  
üìè **Dimensi√≥n (slice)**: `1024`"""
)

# --- Main -------------------------------------------------------------------

st.title("üîé Buscador inteligente de contratos p√∫blicos")
query = st.text_input("¬øQu√© tipo de contrato p√∫blico deseas buscar?")
col_btn, col_k = st.columns([1, 1])
with col_k:
    top_k = st.number_input("Top‚ÄëK", 1, MAX_TOP_K, value=DEFAULT_TOP_K, step=1)
with col_btn:
    do_search = st.button("Buscar", use_container_width=True)

# ===================== EMBEDDINGS / VECTORSTORE HELPERS ======================

def sliced_embedder_factory(api_key: str):
    """Devuelve un wrapper de OpenAIEmbeddings recortado a EMBEDDING_DIM."""
    os.environ["OPENAI_API_KEY"] = api_key  # Garantiza que langchain lo vea
    base = OpenAIEmbeddings(model=EMBEDDING_MODEL)

    class _Wrapper:
        def embed_documents(self, texts):
            return [v[:EMBEDDING_DIM] for v in base.embed_documents(texts)]
        def embed_query(self, text):
            return base.embed_query(text)[:EMBEDDING_DIM]
    return _Wrapper()

# =========================== PROMPTS & CHAINS ================================

prompt_reformulador = PromptTemplate.from_template(
    """
Eres un asistente especializado exclusivamente en encontrar contratos p√∫blicos de bienes o servicios.

1. Reformula la consulta del usuario para que sea clara y √∫til para una b√∫squeda sem√°ntica.
2. Detecta la intenci√≥n:
   ‚Ä¢ "busqueda por codigo" si contiene un c√≥digo de contrataci√≥n.
   ‚Ä¢ "busqueda por servicio" si describe un bien o servicio.
   ‚Ä¢ "fuera del dominio" si no es contrataci√≥n p√∫blica.
   ‚Ä¢ "no entendida" si no puedes determinar.

Devuelve **solo** JSON:
{{
  "consulta_reformulada": "...",
  "intencion": "..."
}}

Entrada del usuario:
"{entrada}"
"""
)
parser_reform = JsonOutputParser()

prompt_validador = PromptTemplate.from_template(
    """
Eres un evaluador que analiza si un concurso p√∫blico est√° relacionado con la consulta:
"{consulta}"

Para cada concurso listado responde con:
- "relevancia": Directamente / Indirecto / No Relacionado.
- "justificacion": breve raz√≥n.

Devuelve JSON:
[
  {{"codigo": "...", "relevancia": "...", "justificacion": "..."}},
  ...
]

{concursos}
"""
)
parser_validador = JsonOutputParser()

# ----- Builder de Chains (se crea despu√©s de tener api_key) -----------------

def build_chains(api_key: str):
    llm_reform  = ChatOpenAI(model="gpt-4", temperature=0, api_key=api_key)
    llm_valida  = ChatOpenAI(model="gpt-4", temperature=0, api_key=api_key)
    return (
        prompt_reformulador | llm_reform | parser_reform,
        prompt_validador    | llm_valida | parser_validador,
    )

# ============================= SEARCH HELPERS ===============================

# --- Regex extracci√≥n de c√≥digos -------------------------------------------

def extraer_codigo_desde_texto(texto: str) -> str:
    patrones = [
        r"\b[A-Z]{0,4}-?\d{2,}-\d{4}(?:-[A-Z0-9]+)*\b",  # CM-60-2025-OEDI
        r"\b\d{2,}-\d{4}\b",                             # 60-2025
        r"\b\d{4}-[A-Z]{2,}\b",                          # 2025-UNPRG
        r"\b[A-Z]{2,}-\d{4}\b",                          # UNPRG-2025
    ]
    for pat in patrones:
        if (m := re.search(pat, texto.upper())):
            return m.group(0)
    return texto.strip()

# --- B√∫squeda por c√≥digo ----------------------------------------------------

def buscar_por_codigo(codigo: str, vs: Chroma) -> List[Dict[str, Any]]:
    patron = re.compile(re.escape(codigo.strip()), re.IGNORECASE)
    data   = vs._collection.get(include=["documents", "metadatas"])
    resultados = []
    for meta, doc in zip(data["metadatas"], data["documents"]):
        cod = meta.get("codigo", "").strip()
        if patron.search(cod):
            resultados.append({
                "codigo":      cod,
                "entidad":     meta.get("entidad", "N/A"),
                "estado":      meta.get("estado", "N/A"),
                "publicacion": meta.get("publicacion", "N/A"),
                "link":        meta.get("link", "N/A"),
                "similitud":   1.0,
                "distancia":   0.0,
                "descripcion": doc[:500] + ("..." if len(doc) > 500 else ""),
            })
    return resultados

# --- B√∫squeda sem√°ntica -----------------------------------------------------

def generar_vector_consulta(texto: str, embedder) -> np.ndarray:
    return np.array(embedder.embed_query(texto)).reshape(1, -1)


def buscar_top_k(vs: Chroma, q_vec: np.ndarray, k: int = 5):
    data = vs._collection.get(include=["embeddings", "documents", "metadatas"])
    emb_valid, docs_valid, metas_valid = [], [], []
    for emb, doc, meta in zip(data["embeddings"], data["documents"], data["metadatas"]):
        try:
            vec = np.array(emb, dtype=np.float32)
            if vec.ndim == 1 and vec.size == EMBEDDING_DIM and not np.isnan(vec).any():
                emb_valid.append(vec)
                docs_valid.append(doc)
                metas_valid.append(meta)
        except Exception:
            continue
    if not emb_valid:
        return []
    sims = cosine_similarity(q_vec, np.vstack(emb_valid))[0]
    top_idx = np.argsort(sims)[-k:][::-1]
    return [(metas_valid[i], docs_valid[i], float(sims[i])) for i in top_idx]


def enriquecer_resultados(top: List[Tuple[Dict[str, Any], str, float]]):
    enr = []
    for rank, (meta, doc, score) in enumerate(top, start=1):
        enr.append({
            "ranking":     rank,
            "codigo":      meta.get("codigo", "N/A"),
            "entidad":     meta.get("entidad", "N/A"),
            "estado":      meta.get("estado", "N/A"),
            "publicacion": meta.get("publicacion", "N/A"),
            "link":        meta.get("link", "N/A"),
            "similitud":   round(score, 4),
            "distancia":   round(1 - score, 4),
            "descripcion": doc[:500] + ("..." if len(doc) > 500 else ""),
        })
    return enr

# ========================== EJECUCI√ìN DE B√öSQUEDA ============================

if do_search:
    # --- Validaciones previas ---------------------------------------------
    if not api_key.strip():
        st.warning("Por favor ingresa tu clave de API.")
        st.stop()
    if not query.strip():
        st.warning("Por favor ingresa una consulta.")
        st.stop()

    # --- Cargar recursos ---------------------------------------------------
    embedder = sliced_embedder_factory(api_key)
    vs       = Chroma(persist_directory=vectorstore_path, embedding_function=embedder)
    try:
        st.sidebar.markdown(f"üóÇÔ∏è **Documentos en colecci√≥n:** {vs._collection.count()}")
    except Exception:
        st.sidebar.markdown("üóÇÔ∏è **Documentos en colecci√≥n:** ?")

    chain_reform, validador_chain = build_chains(api_key)

    # --- Paso 1: Reformulaci√≥n + intenci√≥n --------------------------------
    with st.spinner("Reformulando consulta ‚Ä¶"):
        try:
            reformado = chain_reform.invoke({"entrada": query})
        except Exception as e:
            st.error(f"‚ùå Error al reformular: {e}")
            st.stop()

    consulta_reform = reformado.get("consulta_reformulada", "").strip()
    intencion       = reformado.get("intencion", "no entendida").lower()

    st.markdown(
        f"""**Consulta reformulada:** `{consulta_reform or '‚Äî'}`  \
**Intenci√≥n detectada:** `{intencion}`"""
    )

    # --- Paso 2: Recuperaci√≥n ---------------------------------------------
    resultados: List[Dict[str, Any]] = []
    if intencion == "fuera del dominio":
        st.info("La consulta no parece relacionada con contrataci√≥n p√∫blica.")
        st.stop()

    elif intencion == "busqueda por codigo":
        codigo = extraer_codigo_desde_texto(consulta_reform or query)
        st.markdown(f"üîç **B√∫squeda por c√≥digo:** `{codigo}`")
        resultados = buscar_por_codigo(codigo, vs)
        if not resultados:
            st.info("No se encontraron concursos con ese c√≥digo.")
            st.stop()

    else:  # B√∫squeda sem√°ntica (servicio u ambigua)
        st.markdown("üîç **B√∫squeda sem√°ntica**")
        q_vec = generar_vector_consulta(consulta_reform or query, embedder)
        top   = buscar_top_k(vs, q_vec, k=top_k)
        if not top:
            st.info("No se encontraron documentos relevantes.")
            st.stop()
        resultados = enriquecer_resultados(top)

    # --- Paso 3: Validaci√≥n / Rerank con GPT‚Äë4 -----------------------------
    with st.spinner("Validando relevancia con GPT‚Äë4 ‚Ä¶"):
        concursos_txt = "\n".join([f"- {c['codigo']}: {c['descripcion'][:120]}" for c in resultados])
        try:
            validados = validador_chain.invoke({
                "consulta":  consulta_reform or query,
                "concursos": concursos_txt,
            })
        except Exception as e:
            st.warning(f"No se pudo validar la relevancia: {e}")
            validados = []

    # Mezclamos resultados con relevancia
    actualizados: List[Dict[str, Any]] = []
    for c in resultados:
        cod_base = c["codigo"].strip().lower()
        match = next((v for v in validados if v["codigo"].strip().lower() in cod_base), None)
        if match and match["relevancia"].lower() != "no relacionado":
            c["relevancia"]    = match["relevancia"]
            c["justificacion"] = match["justificacion"]
            actualizados.append(c)

    if not actualizados:
        st.info("GPT‚Äë4 consider√≥ todos los resultados como no relacionados.")
        st.stop()

    # ------------------------- Mostrar resultados --------------------------
    df = pd.DataFrame(actualizados)
    st.dataframe(df, use_container_width=True, hide_index=True)

    # --------------------- Visualizaci√≥n PCA opcional ----------------------
    if show_pca and len(actualizados) >= 3 and intencion != "busqueda por codigo":
        ids = [c["codigo"] for c in actualizados]
        try:
            emb_data = vs._collection.get(ids=ids, include=["embeddings"])
            emb_valid = [e for e in emb_data["embeddings"] if isinstance(e, list) and len(e) == EMBEDDING_DIM]
        except Exception:
            emb_valid = []

        if len(emb_valid) >= 3:
            pts3d = PCA(n_components=3).fit_transform(np.array(emb_valid))
            fig = go.Figure(go.Scatter3d(
                x=pts3d[:, 0], y=pts3d[:, 1], z=pts3d[:, 2],
                mode="markers+text",
                text=[f"{c['codigo']}<br>{c['similitud']:.3f}" for c in actualizados[:len(pts3d)]],
                marker=dict(size=5)
            ))
            fig.update_layout(margin=dict(l=0, r=0, b=0, t=30))
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("No se pudo generar la gr√°fica 3D (menos de 3 embeddings v√°lidos).")

# ============================= PRUEBAS B√ÅSICAS ===============================

if __name__ == "__main__":
    # Pruebas r√°pidas de utilidades (no Streamlit)
    assert extraer_codigo_desde_texto("Necesito CM-60-2025-OEDI") == "CM-60-2025-OEDI"
    assert extraer_codigo_desde_texto("Busco 60-2025") == "60-2025"
    assert extraer_codigo_desde_texto("2025-UNPRG") == "2025-UNPRG"
    assert extraer_codigo_desde_texto("UNPRG-2025") == "UNPRG-2025"
    print("‚úîÔ∏è Tests locales de extracci√≥n de c√≥digos superados.")

